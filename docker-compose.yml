version: "3"

services:
  postgres:
    image: in-sylva-postgres:latest
    volumes:
      - ./data.sql:/docker-entrypoint-initdb.d/data.sql
      - ./postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_MULTIPLE_DATABASES: insylva, keycloak
      POSTGRES_USER: insylva_admin_pg
      POSTGRES_PASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
    ports:
      - "5432:5432"
    networks:
      - app-network
  keycloak:
    image: in-sylva.keycloak:latest
    environment:
      DB_VENDOR: POSTGRES
      DB_ADDR: postgres
      DB_DATABASE: keycloak
      DB_USER: insylva_admin_pg
      DB_SCHEMA: public
      DB_PASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
      KEYCLOAK_USER: insylva_admin
      KEYCLOAK_PASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
      # Uncomment the line below if you want to specify JDBC parameters. The parameter below is just an example, and it shouldn't be used in production without knowledge. It is highly recommended that you read the PostgreSQL JDBC driver documentation in order to use it.
      #JDBC_PARAMS: "ssl=true"
    ports:
      - 7000:8080
    depends_on:
      - postgres
    networks:
      - app-network
  pgadmin:
    image: dpage/pgadmin4
    deploy:
      resources:
        limits:
          cpus: "0.20"
          memory: 10000M
    environment:
      PGADMIN_DEFAULT_EMAIL: aytac.ozkan@inra.fr
      PGADMIN_DEFAULT_PASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
    volumes:
      - pgadmin:/root/.pgadmin
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    networks:
      - app-network
    restart: unless-stopped

  mongo:
    image: mongo:latest
    container_name: in_sylva_mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: in_sylva_mongoc
      MONGO_INITDB_ROOT_PASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
      MONGO_INITDB_DATABASE: insylva
    ports:
      - 27017:27017
    volumes:
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - app-network
    restart: unless-stopped

  mongo-express:
    image: mongo-express
    restart: always
    ports:
      - 8881:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: in_sylva_mongoc
      ME_CONFIG_MONGODB_ADMINPASSWORD: v2kGBDUaGjXK2VuPyf5R64VS
    networks:
      - app-network
    restart: unless-stopped

  odfe-node1:
    image: amazon/opendistro-for-elasticsearch:1.3.0
    container_name: odfe-node1
    environment:
      - cluster.name=odfe-cluster
      - node.name=odfe-node1
      - discovery.seed_hosts=odfe-node1,odfe-node2
      - cluster.initial_master_nodes=odfe-node1,odfe-node2
      - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
      - network.host=0.0.0.0
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536 # maximum number of open files for the Elasticsearch user, set to at least 65536 on modern systems
        hard: 65536
    volumes:
      - odfe-data1:/usr/share/elasticsearch/data
      - ./root-ca.pem:/usr/share/elasticsearch/config/root-ca.pem
      - ./node.pem:/usr/share/elasticsearch/config/node.pem
      - ./node-key.pem:/usr/share/elasticsearch/config/node-key.pem
      - ./admin.pem:/usr/share/elasticsearch/config/admin.pem
      - ./admin-key.pem:/usr/share/elasticsearch/config/admin-key.pem
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml
      - ./roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml
      - ./tenants.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/tenants.yml
      - ./roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml
      - ./action_groups.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/action_groups.yml
    ports:
      - 9200:9200
      - 9600:9600 # required for Performance Analyzer
    networks:
      - app-network
    restart: unless-stopped

  odfe-node2:
    image: amazon/opendistro-for-elasticsearch:1.3.0
    container_name: odfe-node2
    environment:
      - cluster.name=odfe-cluster
      - node.name=odfe-node2
      - discovery.seed_hosts=odfe-node1,odfe-node2
      - cluster.initial_master_nodes=odfe-node1,odfe-node2
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - network.host=0.0.0.0
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - odfe-data2:/usr/share/elasticsearch/data
      - ./root-ca.pem:/usr/share/elasticsearch/config/root-ca.pem
      - ./node.pem:/usr/share/elasticsearch/config/node.pem
      - ./node-key.pem:/usr/share/elasticsearch/config/node-key.pem
      - ./admin.pem:/usr/share/elasticsearch/config/admin.pem
      - ./admin-key.pem:/usr/share/elasticsearch/config/admin-key.pem
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml
      - ./roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml
      - ./tenants.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/tenants.yml
      - ./roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml
      - ./action_groups.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/action_groups.yml
    networks:
      - app-network
    restart: unless-stopped

  kibana:
    image: amazon/opendistro-for-elasticsearch-kibana:1.3.0
    container_name: odfe-kibana
    environment:
      - network.host=0.0.0.0
    ports:
      - 5601:5601
    volumes:
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml
    environment:
      ELASTICSEARCH_URL: https://odfe-node1:9200
      ELASTICSEARCH_HOSTS: https://odfe-node1:9200
    networks:
      - app-network
    restart: unless-stopped

  gatekeeper:
    image: in-sylva.gatekeeper:latest
    container_name: in-sylva.gatekeeper
    environment:
      - network.host=0.0.0.0
    ports:
      - 4000:4000
    networks:
      - app-network
    restart: unless-stopped

  source-manager:
    image: in-sylva.source.manager:latest
    container_name: in-sylva.source.manager
    environment:
      - network.host=0.0.0.0
    ports:
      - 5000:5000
    networks:
      - app-network
    restart: unless-stopped

  portal:
    image: in-sylva.portal:latest
    container_name: in-sylva.portal
    environment:
      - network.host=0.0.0.0
    ports:
      - 3000:3000
    networks:
      - app-network
    restart: unless-stopped

  portainer:
    image: portainer/portainer
    command: -H unix:///var/run/docker.sock
    restart: always
    ports:
      - 9000:9000
      - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data

volumes:
  postgres-data:
  pgadmin:
  odfe-data1:
  odfe-data2:
  portainer_data:
networks:
  app-network:
    driver: bridge
